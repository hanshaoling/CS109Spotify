{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spotlight.interactions import Interactions\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = path = '/Users/haoxinli/DocumentsLocal/Spotify/mpd.v1/data/'\n",
    "playlist_fn = os.listdir(data_path)\n",
    "\n",
    "## Preparing data\n",
    "\n",
    "CF_baseline_Train = []\n",
    "CF_baseline_Val = []\n",
    "\n",
    "counter = 0\n",
    "for fn_index in range(100):\n",
    "    with open(data_path+playlist_fn[fn_index]) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    playlists = data['playlists']\n",
    "\n",
    "    for playlist in playlists:\n",
    "        pid = playlist['pid']\n",
    "        for song in playlist['tracks']:\n",
    "            track_uri = song['track_uri'].split(':')[2]\n",
    "            if counter < 80:\n",
    "                CF_baseline_Train.append([pid,track_uri])\n",
    "            else:\n",
    "                CF_baseline_Val.append([pid,track_uri])\n",
    "    counter += 1\n",
    "\n",
    "with open(\"CF_baseline_Train_80000.json\", \"w\") as f:\n",
    "    data_json = json.dump(CF_baseline_Train,f)\n",
    "    \n",
    "with open(\"CF_baseline_Val_20000.json\", \"w\") as f:\n",
    "    data_json = json.dump(CF_baseline_Val,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CF_baseline_Train_40000.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "users = [user for user, song in data]\n",
    "item = [song for user, song in data]\n",
    "\n",
    "## Assign id to each playlist title\n",
    "\n",
    "song_per_user = {}\n",
    "for user in users:\n",
    "    if user not in song_per_user.keys():\n",
    "        song_per_user[user] = 1\n",
    "    else:\n",
    "        song_per_user[user] += 1\n",
    "# print(len(song_per_user))\n",
    "\n",
    "\n",
    "\n",
    "pids = {}\n",
    "num = 0\n",
    "for user in song_per_user.keys():\n",
    "    pids[user] = num\n",
    "    num += 1\n",
    "# print(len(pids))\n",
    "    \n",
    "    \n",
    "users_transform = []\n",
    "for user in users:\n",
    "    users_transform.append(pids[user])\n",
    "# print(len(users_transform))\n",
    "    \n",
    "    \n",
    "## Assign id to each track id\n",
    "# appearance of each track\n",
    "count = {}\n",
    "for i in item:\n",
    "    if i not in count.keys():\n",
    "        count[i] = 1\n",
    "    else:\n",
    "        count[i] = count[i] + 1\n",
    "# print(len(count))\n",
    "        \n",
    "        \n",
    "item_id = {}\n",
    "id = 0\n",
    "for i in count.keys():\n",
    "    item_id[i] = id\n",
    "    id = id+1\n",
    "# print(len(item_id))\n",
    "\n",
    "\n",
    "item_transformed = []\n",
    "for i in item:\n",
    "    item_transformed.append(item_id[i])\n",
    "# print(len(item_transformed))\n",
    "    \n",
    "\n",
    "ratings = np.ones(len(item_transformed))\n",
    "\n",
    "# prepare the interaction matrix\n",
    "# data = Interactions(np.array(users_transform), np.array(item_transformed), ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CF_baseline_Train_40000.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImplicitFactorizationModel(n_iter = 5)\n",
    "model.fit(data, verbose = 1)\n",
    "torch.save(model, 'baseline_model_40000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('baseline_model_40000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CF_baseline_Val_10000.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "validation = []\n",
    "\n",
    "playlist_num = data[0][0]\n",
    "songs = []\n",
    "for item in data:\n",
    "    playlist_num_new = item[0]\n",
    "    if playlist_num_new == playlist_num:\n",
    "        songs.append(item[1])\n",
    "        playlist_num = playlist_num_new\n",
    "    else:\n",
    "        validation.append(songs)\n",
    "        songs = []\n",
    "        songs.append(item[1])\n",
    "        playlist_num = playlist_num_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation x and y\n",
    "X_val = []\n",
    "y_val = []\n",
    "for i in range(len(validation)):\n",
    "    playlist = validation[i]\n",
    "    x, y = train_test_split(playlist, train_size = 0.7)\n",
    "    X_val.append(x)\n",
    "    y_val.append(y)\n",
    "with open(\"/Users/haoxinli/DocumentsLocal/Spotify/X_validation.json\", \"w\") as f:\n",
    "    data_json = json.dump(X_val,f)\n",
    "with open(\"/Users/haoxinli/DocumentsLocal/Spotify/y_validation.json\", \"w\") as f:\n",
    "    data_json = json.dump(y_val,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load top 500 tracks\n",
    "top_500 = pd.read_csv('/Users/haoxinli/DocumentsLocal/Spotify/top_500.csv').iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = {}\n",
    "for i in range(100):\n",
    "    track_uri = top_500[i].split(':')[2]\n",
    "    top_100[track_uri] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "users = np.array(range(40000))\n",
    "\n",
    "with open('/Users/haoxinli/DocumentsLocal/Spotify/X_validation.json', 'r') as f:\n",
    "    validation = json.load(f)\n",
    "\n",
    "length = 1000\n",
    "\n",
    "rec = []\n",
    "\n",
    "for i in tqdm(range(length)):\n",
    "    playlist=validation[i]\n",
    "    a = []\n",
    "    for item in playlist:\n",
    "        try:\n",
    "            a.append(item_id[item])\n",
    "        except:\n",
    "            pass\n",
    "    if len(a) > 1:\n",
    "    \n",
    "        dic = {}\n",
    "        score = np.array([0] * len(model.predict(1)))\n",
    "        sum_w = 0\n",
    "\n",
    "        new_user = np.array(a)\n",
    "        random.shuffle(users)\n",
    "        users = users[0:1000]\n",
    "        for i in users:\n",
    "            s = model.predict(i, np.array(new_user))\n",
    "            cos_sim = cosine_similarity(np.array([s]),np.array([new_user]))\n",
    "            sum_cos = sum_cos + cos_sim\n",
    "            score = cos_sim * model.predict(i) + score\n",
    "        score = score / sum_cos\n",
    "\n",
    "        for index in np.argsort(score)[-1:-101:-1]:\n",
    "            dic[id_to_track[index]] = score[index]\n",
    "        rec.append(dic)\n",
    "\n",
    "    else:\n",
    "        rec.append(top_100)\n",
    "\n",
    "            \n",
    "with open('/Users/haoxinli/DocumentsLocal/Spotify/CF_recommended_song.json', 'w') as f:\n",
    "    json.dump(rec, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation\n",
    "with open('/Users/haoxinli/DocumentsLocal/Spotify/y_validation.json', 'r') as f:\n",
    "    y_validation = json.load(f)\n",
    "with open('/Users/haoxinli/DocumentsLocal/Spotify/CF_recommended_song.json', 'r') as f:\n",
    "    recs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/haoxinli/DocumentsLocal/Spotify/CF_recommended_song.json', 'r') as f:\n",
    "    recommendation = json.load(f)\n",
    "    \n",
    "R_precision_scores = []\n",
    "NDCG_scores = []\n",
    "\n",
    "with open('/Users/haoxinli/DocumentsLocal/Spotify/y_validation.json') as json_file: \n",
    "    val_Y = json.load(json_file)  \n",
    "for i in range(500):\n",
    "    rec = recommendation[i][:100]\n",
    "    Y = val_Y[i]\n",
    "    R_precision_scores.append(R_precision(rec,Y))\n",
    "    NDCG_scores.append(NDCG(rec,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_precision(rec, Y):\n",
    "    return len(intersection(recommendation, Y))/len(Y)\n",
    "\n",
    "def NDCG(rec, Y):\n",
    "    IDCG = 0\n",
    "    for i in range(0,len(Y)):\n",
    "        if i == 0: IDCG += 1\n",
    "        else: IDCG += 1/math.log((i+2),2)\n",
    "    DCG = 0\n",
    "    for i in range(0,len(rec)):\n",
    "        if i == 0 and rec[i] in Y: DCG += 1\n",
    "        elif i > 0 and rec[i] in Y: DCG += 1/math.log((i+2),2)     \n",
    "    return DCG/IDCG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03394676679529621"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(R_precision_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013247911605909105"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(NDCG_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_norm = audio_features_norm.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_values = audio_features_norm.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         spotify:track:0UaMYEvWZi0ZqiDOoHU3YI\n",
       "1         spotify:track:6I9VzXrHxO9rA9A5euc8Ak\n",
       "2         spotify:track:0WqIKmW4BTrj3eJFmnCKMv\n",
       "3         spotify:track:1AWQoqb9bSvzTjaLralEkT\n",
       "4         spotify:track:1lzr43nnXAijIGYnCT8M8H\n",
       "                          ...                 \n",
       "681782    spotify:track:3xLmarzSroQuXbTK44UXhD\n",
       "681783    spotify:track:3ryw10oCE4NhNbanwrzurQ\n",
       "681784    spotify:track:1kUoHfeBjoChgOPeBjFELn\n",
       "681785    spotify:track:37IrFeTPLJs1IKxoBDuN8b\n",
       "681786    spotify:track:6v0CoPvaaJqWo67GTSPBc1\n",
       "Name: track_id, Length: 681787, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trackid = audio_features_norm['track_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CF + content\n",
    "def hybrid(recommendation, validation):\n",
    "    \n",
    "    hybrid_rec = []\n",
    "    for i in tqdm(range(len(recommendation))):\n",
    "#         print(hybrid_rec)\n",
    "        dictionary = {}\n",
    "        rec_playlist=recommendation[i].copy()\n",
    "        test_val = validation[i].copy()\n",
    "\n",
    "        for song in rec_playlist[:100]:\n",
    "            score = 0\n",
    "            song_pos = np.where(trackid == 'spotify:track:' + song)[0]\n",
    "            for truth_song in test_val:\n",
    "                truth_song_pos = np.where(trackid == 'spotify:track:' + truth_song)[0]\n",
    "                try:\n",
    "                    score = score + cosine_similarity(audio_features_values[truth_song_pos], audio_features_values[song_pos])[0][0]\n",
    "                except:\n",
    "                    pass\n",
    "            dictionary[song] = score\n",
    "            dictionary = {k: v for k, v in sorted(dictionary.items(), key=lambda item: item[1], reverse=True)}\n",
    "        hybrid_rec.append(dictionary)\n",
    "    return hybrid_rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/haoxinli/DocumentsLocal/Spotify/CF_recommended_song.json', 'r') as f:\n",
    "    recommendation = json.load(f)\n",
    "with open(\"/Users/haoxinli/DocumentsLocal/Spotify/X_validation.json\", \"r\") as f:\n",
    "    validation = json.load(f)\n",
    "\n",
    "hybrid_rec = hybrid(recommendation, validation[:1000])\n",
    "# with open('/Users/haoxinli/DocumentsLocal/Spotify/hybrid_rec.json', 'w') as f:\n",
    "#     json.dump(hybrid_rec, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/haoxinli/DocumentsLocal/Spotify/hybrid_rec.json', 'r') as f:\n",
    "    hybrid_rec = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033521005525262486\n",
      "0.012958842807103098\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "hybrid_recommendation = [list(single_score.keys())[:100] for single_score in hybrid_rec]\n",
    "R_precision_scores = []\n",
    "NDCG_scores = []\n",
    "\n",
    "with open('/Users/haoxinli/DocumentsLocal/Spotify/y_validation.json') as json_file: \n",
    "    val_Y = json.load(json_file)  \n",
    "for i in range(1000):\n",
    "    rec = hybrid_recommendation[i][:100]\n",
    "    Y = val_Y[i]\n",
    "    R_precision_scores.append(R_precision(rec,Y))\n",
    "    NDCG_scores.append(NDCG(rec,Y))\n",
    "\n",
    "print(np.mean(R_precision_scores))\n",
    "print(np.mean(NDCG_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
